<h2 align='center'> Recipe Infusion </h2>

<p> In this project we aim to create a framework to generate style infused cooking recipes from a list of ingredient inputs. Our model utilizes two finetuned Large Language Models(LLMs), DistilGPT2, and T5. DistilGPT2 is used to generate recipes, and T5 is used as a style transfer model to infuse the language style of different personas to the generated recipe. </p>

### Table of Contents

1. [Dataset Information](#dataset_info)
2. [Dependencies](#depend)
3. [Files](#files)
4. [How to Run](#run)

### Dataset Information<a name="dataset_info"></a>
* Recipe Generation
  * RecipeNLG : https://recipenlg.cs.put.poznan.pl/
  * RecipeBox : https://eightportions.com/datasets/Recipes/
* Text Style Transfer
  * William Shakespeare : 
      * Translations of Shakespeare plays to Modern English 
      * https://www.kaggle.com/datasets/garnavaurha/shakespearify
  * Taylor Swift : 
      * Taylor Swift Song Lyrics
      * https://www.kaggle.com/datasets/PromptCloudHQ/taylor-swift-song-lyrics-from-all-the-albums
  * Donald Trump : 
      * Donal Trump tweets through June 2020
      * https://www.kaggle.com/datasets/austinreese/trump-tweets
  * Michael Scott : 
      * Complete script of The Office
      * https://www.kaggle.com/datasets/nasirkhalid24/the-office-us-complete-dialoguetranscript 

### Dependencies<a name="depend"></a>
1. Numpy : Perform several mathematical evaluations in the preprocessing of the datasets

    pip install numpy  
2. Pandas : Loading/Processing/Storing of the different datasets

    pip install pandas 
3. Itertools : Easy iteration of large lists 

    pip install itertools 
4.  Sklearn : Cosine Similarity and TF-IDF

    pip install sklearn 
5. Transformers : DistilGPT2, T5-small, MarianMT (both model and tokenizers)

    pip install transformers 
6. SentencePiece : Used by MarianMT's tokenizer (Back Translation)

    pip install sentencepiece  
7. Evaluate : BLEU Score evaluation 

    pip install evaluate   
8. Matplotlib: Plotting of the training curves 

    pip install matplotlib

### Files<a name="files"></a>
* RecipeDataset.ipynb : 
     * Loading of both Recipes datasets 
     * Preprocessing the datasets to get into a common useful format 
     * Performing statistical analysis on the data
     * Storing the final concatenated dataset 
* Statistics.ipynb :
     * Statistical analysis on the preprocessed datasets and the final concatenated dataset 
* Recipe_Generation_DistilGPT.ipynb :
     * Loading of the final recipe dataset 
     * Data Preparation of the final dataset 
     * Training of DistilGPT2 Model 
     * Testing of the Finetuned (FT) model and baseline model 
     * Evaluation of the models - BLEU Score and Perplexity 
     * Generation of Recipe dataset for Style Transfer
     * Error Analysis on Adversarial inputs  
* Preprocess_TST_dataset.ipynb : 
     *  Loading the non-parallel data - Taylor and Trump
     *  Preprocess the datasets
     *  Extract some statistical info about the dataset 
* Shakespeare_and_Scripts_Preprocessing.ipynb : 
     *  Loading the non-parallel data - Michael 
     *  Load the parallel data -  Shakespeare 
     *  Preprocess the datasets
     *  Extract some statistical info about the dataset
* BackTranslation.ipynb :
     * Load the MarianMT models for Fr-En and En-Fr
     * Perform back translation to generate synthetic parallel data - Michael, Taylor and Trump
     * Store the parallel dataset  
* TST_Architecture.ipynb :
     * Load all the parallel datasets 
     * Finetune a different T5-small model on each dataset 
     * Generate styled recipes - Sentence-wise and Entire Recipe
     * Test the performance (Human Evaluation) on the styled recipes (Sentence-wise)
     * Check for style infusion on random sentences 
 * Supplementary/Adversarial Inputs.xlsx
     * Adversarial Examples to the model. Contains 120 examples for which model's output differs from the expected behavior and is of low quality 
 * Supplementary/Sentence_Styled_Recipes.xlsx
      * Human Evaluations on the Styled Recipes generated by the Fine tuned T5 model   
### How to Run<a name="run"></a>
Except training (due to computational limitations) of the LLMs all of the code was implemented in Google Colab. We have listed the steps that needed to be followed for a successful implementation of the project.
1) Download all the .ipynb files and upload them in a new folder on Google Drive named 'Project 685'
2) Download all the Recipe Datasets and upload the zip files on the Drive
3) Run RecipeDataset.ipynb to get the 'Final_dataset' file, which consists of the preprocessed concatenated dataset
4) Run Statistics.ipynb file to know some statistics about the datasets [OPTIONAL]
5) Run Recipe_Generation_DistilGPT.ipynb to get the finetuned recipe generation model and Recipe generations 
6) Download the Text Style Transfer datasets. Create a new sub-folder {persona}_TST. For example, Taylor_TST
7) Upload the datasets for Taylor and Trump in the sub-folder, whereas for Shakespeare and Michael in the main folder
8) Run the Preprocess_TST_dataset.ipynb and Shakespeare_and_Scripts_Preprocessing.ipynb to get the appropriate formatted dataset for Back translation
9) Run BackTranslation.ipynb to get a parallel dataset for Taylor, Trump and Shakespeare
10) Run TST_Architecture.ipynb file to get the finetuned TST models

